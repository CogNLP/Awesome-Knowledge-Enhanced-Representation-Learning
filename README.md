## Awesome Knowledge-Enhanced Natural Language Understanding

An awesome repository for knowledge-enhanced natural language understanding resources, including related papers, codes and datasets. Inspired by [KENLG-Reading](https://github.com/wyu97/KENLG-Reading).



## Basic NLU Papers for Beginners

+ Attention is All you Need, at NeurIPS 2017. \[[pdf](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\]
+ BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, on arXiv 2019. \[[pdf](https://arxiv.org/pdf/1810.04805.pdf)\]
+ SpanBERT: Improving Pre-training by Representing and Predicting Spans, at TACL 2020. \[[pdf](https://watermark.silverchair.com/tacl_a_00300.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAswwggLIBgkqhkiG9w0BBwagggK5MIICtQIBADCCAq4GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMJSdEoxhDp2Vfkr4iAgEQgIICf3hP52SfBNJNCTxJA-VRo3ExIlGOLIddPfSj3IcpRWHHerFFqRl-orIB1rTw9CnQtr7OTZ-9JtUg0ut9qyj68gIut_7Atb8SU-rjzLGkeh2j0qpvYNzXOyJIdY-6d6E0zwWt1JPyV2G3fUIUfEtPRj0jl5ZfvyqdIq-nQG2eQM8L6A5y3mVsZx3LqNvNJSupvajaR9FmpyjWtgByta-dCnOahgnmuMGxFiPWqeYNrtawb18DycLI1bXwUHIMEvjrFUT1A_ouu7yvYovl8HQspQV-S2-Gl_RDwQ_wSSXgZznNiAaEva3C9Ajl7ZLJH3HXNUw3HQJSoBcntQmhWrylC-HIJ3BxSg5SfC9V4fhMY7ZzGkNKVOB0N6mziE-iBl57K8kezvcgPyACF9SDNNbgp3TO3CCN75etIdEMXSVpV17Ehut_HdK77lAfUcxspKE3KnRWsOfdh477xYdw-I5RVoSEtNtimj_YVw7KHGbEgBzZyMamqxhnqseElBoPOPpj67BX4NeN6kKteH1c4fzD00rDr834KYi5hi_5bXwxKCkc_nDBPdQp-3YolCGz5Z2WkEFj187JlkaftqJNf_NVhxYf1WTANc-7k5wMMXJlC-KNR60mieHWoCHQZIlwBuPQq-oI055JcGI4yI91objvBvCH8BOSYdACbnlGR_wsZxxfCFaNcYqaMqVY1t5OZFxqY2Q5ACRwzYu19GjFE-jPfXhGW84PF-NqsVpKJbJxywKfseHEpi8m86rP-eObzAlBiplhD9s9zkjy0pbM0P-ab5A2dOruqN1A_XDMOoKqEiKJIb_gbmaNHfk61HvzU4ZY3H8wDwsWQIRJRkaoJEBbLw)\]

## KENLU Survey
- Does Knowledge Help General NLU? An Empirical Study, on arXiv 2021. [[pdf](https://arxiv.org/pdf/2109.00563.pdf)]

## Knowledge-Enhanced Pre-training
+ **[Survey]** A Survey of Knowledge Enhanced Pre-trained Models, on arXiv 2022. \[[pdf](https://arxiv.org/pdf/2110.00269.pdf)\]
+ **[Survey]** Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey, on arXiv 2021. \[[pdf](https://arxiv.org/pdf/2110.08455.pdf)\]
+ **[Survey]** Relational World Knowledge Representation in Contextual Language Models: A Review, at EMNLP 2021. \[[pdf](https://aclanthology.org/2021.emnlp-main.81.pdf)\]
+ **[Survey]** Combining pre-trained language models and structured knowledge, on arXiv 2021. \[[pdf](https://arxiv.org/pdf/2101.12294.pdf)\]
+ Dict-BERT: Enhancing Language Model Pre-training with Dictionary, on arXiv 2022. \[[pdf](https://arxiv.org/pdf/2110.06490.pdf)\]
+ **[Commonsense Knowledge]** Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models, on arXiv 2020. \[[pdf](https://arxiv.org/pdf/1908.06725.pdf)\]

## Knowledge-Enhanced Text Representation
- Incorporating Extra Knowledge to Enhance Word Embedding, at IJCAI 2021. \[[pdf](https://www.ijcai.org/proceedings/2020/0686.pdf)\]
- **[Entity Knowledge]** LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention, at EMNLP 2020. \[[pdf](https://aclanthology.org/2020.emnlp-main.523.pdf)\]
- Knowledge Enhanced Contextual Word Representations, at EMNLP 2019. \[[pdf](https://aclanthology.org/D19-1005.pdf)\]
- Event Representation Learning Enhanced with External Commonsense Knowledge, at EMNLP 2019. \[[pdf](https://aclanthology.org/D19-1495.pdf)\]
- Offline versus Online Representation Learning of Documents Using External Knowledge, at TOIS 2019. \[[pdf](https://dl.acm.org/doi/abs/10.1145/3349527?casa_token=FQdaxs1gjN8AAAAA:YqIzQLc4hL-4mQZfevD6FV_FCF2JH2sCpKns49WpuqTRwPBHO_oqfhhESj5Kgb9LHGXjIu59yIalkg)\]


## Knowledge-Enhanced Text Classification
+ Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification, at ACL 2022. [[pdf](https://arxiv.org/pdf/2108.02035.pdf)]
+ KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling, on arXiv 2022. [[pdf](https://arxiv.org/pdf/2203.06835.pdf)]
+ KESA: A Knowledge Enhanced Approach For Sentiment Analysis, on arXiv 2022. \[[pdf](https://arxiv.org/pdf/2202.12093.pdf)\]
+ **[Entity Knowledge]**  **[Fact Verification]** Modeling Entity Knowledge for Fact Verification, at FEVER 2021. [[pdf](https://aclanthology.org/2021.fever-1.6.pdf)]
+ Knowledge-Guided Paraphrase Identification, at EMNLP findings 2021. [[pdf](https://aclanthology.org/2021.findings-emnlp.72.pdf)]
+ KinGDOM: Knowledge-Guided DOMain adaptation for sentiment analysis, at ACL 2020. [[pdf](https://aclanthology.org/2020.acl-main.292.pdf)]

## Knowledge-Enhanced Information Extraction
- Enhanced Language Representation with Label Knowledge for Span Extraction, at EMNLP 2021. [[pdf](https://aclanthology.org/2021.emnlp-main.379.pdf)] 
- Knowledge-Enriched Event Causality Identification via Latent Structure Induction Networks, at ACL 2021. [[pdf](https://aclanthology.org/2021.acl-long.376.pdf)]
- Fine-grained Information Extraction from Biomedical Literature based on Knowledge-enriched Abstract Meaning Representation, at ACL 2021. [[pdf](https://aclanthology.org/2021.acl-long.489.pdf)]
- Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference, at ACL 2021. [[pdf](https://aclanthology.org/2021.acl-long.488.pdf)]
- Metadata Shaping: Natural Language Annotations for the Tail, on arXiv 2021. [[pdf](https://arxiv.org/pdf/2110.08430.pdf)]
- Knowledge Enhanced Event Causality Identification with Mention Masking Generalizations, at IJCAI 2020. [[pdf](https://www.ijcai.org/proceedings/2020/0499.pdf)] 

## Knowledge-Enhanced Information Retrieval
- LET: Linguistic Knowledge Enhanced Graph Transformer for Chinese Short Text Matching, at AAAI 2021. [[pdf](https://ojs.aaai.org/index.php/AAAI/article/view/17592)]
- Learning Unsupervised Knowledge-Enhanced Representations to Reduce the Semantic Gap in Information Retrieval, at TIOS 2020. [[pdf](https://dl.acm.org/doi/abs/10.1145/3417996)]
- Knowledge Enhanced Hybrid Neural Network for Text Matching, at AAAI 2018. [[pdf](https://openreview.net/forum?id=ryZBFeZ_-H)]

## Knowledge-Enhanced Question Answering
+ Unstructured Text Enhanced Open-Domain Dialogue System: A Systematic Survey, at TOIS 2022. [[pdf](https://dl.acm.org/doi/abs/10.1145/3464377?casa_token=y4ngVLYx2WsAAAAA:mu1ibata4LRdqibfIQ0iyecpzA5gEdz7WJYoLOFebukQg7mPvU5GDTaZz9GfL7Ce5PuGgnY9_67sVQ)]
+ Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition, at EMNLP 2020. [[pdf](https://aclanthology.org/2020.emnlp-main.372.pdf)]

## Other Related Projects
- **[Survey]** **[Prompt]** Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing, on arXiv 2021. [[pdf](https://arxiv.org/pdf/2107.13586.pdf)]
- Knowledge-enriched Text Generation Survey, Tutorial and Reading, on github. [[home](https://github.com/wyu97/KENLG-Reading)]
- A Survey of Knowledge-Enhanced Text Generation, on arXiv 2020. [[pdf](https://arxiv.org/pdf/2010.04389.pdf)]

